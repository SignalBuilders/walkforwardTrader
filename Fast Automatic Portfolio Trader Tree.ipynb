{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import params\n",
    "from google.cloud import datastore, storage, logging\n",
    "import time\n",
    "import pickle\n",
    "import hashlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import portfolioGeneration\n",
    "import portfolio\n",
    "import dataAck\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing as mp \n",
    "import autoPortfolioTree\n",
    "import curveTreeDB\n",
    "import portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataObjs = curveTreeDB.getValidModels(params.treeModels, returnEntireObject=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allModels = []\n",
    "tickersSeen = []\n",
    "for item in dataObjs:\n",
    "    try:\n",
    "        if item[\"IS_PROFITABILITY SLIPPAGE\"] > 0.51 and item[\"IS_ANNUALIZED RETURN\"] > 0.10:\n",
    "            model = item[\"model\"]\n",
    "            print(model.targetTicker, model.getHash(), item[\"IS_SHARPE SLIPPAGE\"], item[\"IS_SHARPE DIFFERENCE SLIPPAGE\"], item[\"IS_BETA\"])\n",
    "            allModels.append(model)\n",
    "            if model.targetTicker not in tickersSeen:\n",
    "                tickersSeen.append(model.targetTicker)\n",
    "    except:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(allModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(tickersSeen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "factorToTrade = \"VTI\"#tickersSeen[random.randint(0, len(tickersSeen) - 1)]\n",
    "factorToTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(dataAck)\n",
    "uniqueModels, modelReturns, modelPredictions, modelSlippageReturns, modelReturnsWithFactor, joinedData = autoPortfolioTree.computeReturnsForUniqueModelsCache(allModels, factorToTrade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanedReturns = modelReturns.fillna(0)\n",
    "cleanedReturns.columns = [item.getHash() for item in uniqueModels]\n",
    "\n",
    "cleanedPredictions = modelPredictions.fillna(0)\n",
    "cleanedPredictions.columns = [item.getHash() for item in uniqueModels]\n",
    "hashToModel = {}\n",
    "for item in uniqueModels:\n",
    "    hashToModel[item.getHash()] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanedReturns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def historicalWeightsToTickerAllocations(historicalWeights, algorithmPredictions, modelsInPortfolio):\n",
    "    aggregatePredictions = algorithmPredictions.dropna()\n",
    "    allocationsToStore = []\n",
    "    historicalAllocations = None\n",
    "    scaledHistoricalAllocations = None\n",
    "    ##ITERATE THROUGH DAYS TO CALCULATE NET POSITION\n",
    "    for i in range(len(historicalWeights)):\n",
    "        netPosition = {}\n",
    "        weights = historicalWeights.iloc[i]\n",
    "        for model in modelsInPortfolio:\n",
    "            if model.targetTicker not in netPosition:\n",
    "                netPosition[model.targetTicker] = 0.0\n",
    "            try:\n",
    "                aggregatePredictions.loc[historicalWeights.index[i]]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            netPosition[model.targetTicker] += weights[model.getHash()] * aggregatePredictions.loc[historicalWeights.index[i]][model.getHash()]\n",
    "        thisDf = pd.DataFrame([netPosition], index=[historicalWeights.index[i]])\n",
    "        if historicalAllocations is None:\n",
    "            historicalAllocations = thisDf\n",
    "        else:\n",
    "            historicalAllocations = pd.concat([historicalAllocations, thisDf])\n",
    "        \n",
    "        totalCapitalUsed = sum([abs(netPosition[ticker]) for ticker in netPosition])\n",
    "        scaledNetPosition = {}\n",
    "        for ticker in netPosition:\n",
    "            scaledNetPosition[ticker] = netPosition[ticker] * 1.0/totalCapitalUsed\n",
    "        \n",
    "        thisDf = pd.DataFrame([scaledNetPosition], index=[historicalWeights.index[i]])\n",
    "        if scaledHistoricalAllocations is None:\n",
    "            scaledHistoricalAllocations = thisDf\n",
    "        else:\n",
    "            scaledHistoricalAllocations = pd.concat([scaledHistoricalAllocations, thisDf])\n",
    "    \n",
    "    return historicalAllocations, scaledHistoricalAllocations\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import empyrical\n",
    "def getLimitedDataForPortfolio(historicalWeights, historicalPredictions, modelsUsed, factorToTrade, joinedData):\n",
    "    \n",
    "    normalTickerAllocationsTable, scaledTickerAllocationsTable = historicalWeightsToTickerAllocations(historicalWeights, historicalPredictions, modelsUsed)\n",
    "    \n",
    "    tickerAllocationsTable = scaledTickerAllocationsTable\n",
    "    rawTickerPerformance = portfolioGeneration.calculatePerformanceForTable(tickerAllocationsTable, tickerAllocationsTable.columns, joinedData)\n",
    "\n",
    "    rawAlgoPerformance = pd.DataFrame(rawTickerPerformance.apply(lambda x:sum(x), axis=1), columns=[\"Algo Return Without Commissions\"])\n",
    "\n",
    "    tickerPerformance, algoPerformance, algoTransactionCost =  portfolioGeneration.calculatePerformanceForAllocations(tickerAllocationsTable, joinedData)\n",
    "\n",
    "    benchmark = factorToTrade\n",
    "    factorReturn = dataAck.getDailyFactorReturn(benchmark, joinedData)\n",
    "    factorReturn.columns = [\"Factor Return (\" + benchmark + \")\"]\n",
    "    algoPerformance.columns = [\"Algo Return\"]\n",
    "    \n",
    "    tickersUsed = []\n",
    "    for mod in modelsUsed:\n",
    "        tickersUsed.append(mod.targetTicker)\n",
    "    \n",
    "#     for ticker in tickersUsed:\n",
    "#         thisFactorReturn = dataAck.getDailyFactorReturn(ticker, joinedData)\n",
    "#         thisFactorReturn.columns = [\"Factor Return (\" + ticker + \")\"]\n",
    "#         alpha, beta = empyrical.alpha_beta(algoPerformance, thisFactorReturn)\n",
    "#         print(ticker, beta)\n",
    "\n",
    "    alpha, beta = empyrical.alpha_beta(algoPerformance, factorReturn)\n",
    "    sharpe_difference = empyrical.sharpe_ratio(algoPerformance) - empyrical.sharpe_ratio(factorReturn)\n",
    "    annualizedReturn = empyrical.annual_return(algoPerformance)[0]\n",
    "    annualizedVolatility = empyrical.annual_volatility(algoPerformance)\n",
    "    \n",
    "    ##AUTOMATICALLY TAKES SLIPPAGE INTO ACCOUNT\n",
    "    return {\n",
    "        \"benchmark\":factorToTrade,\n",
    "        \"alpha\":alpha,\n",
    "        \"beta\":beta,\n",
    "        \"sharpe difference\":sharpe_difference,\n",
    "        \"annualizedReturn\":annualizedReturn,\n",
    "        \"annualizedVolatility\":annualizedVolatility,\n",
    "        \"sharpe\":empyrical.sharpe_ratio(algoPerformance),\n",
    "        \"free return\":annualizedReturn - annualizedVolatility\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returnSelectAlgos(algoColumns):\n",
    "    return np.random.choice(algoColumns, size=random.randint(15, 30), replace= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hrpPortfolioOpt as hrp\n",
    "def produceHRPPredictions(aggregateReturns, windowSize, startIndex, maxWindowSize = False):\n",
    "    hrpReturns = pd.DataFrame([])\n",
    "    historicalWeights = pd.DataFrame([])\n",
    "    i = windowSize\n",
    "    if startIndex is not None:\n",
    "        i = startIndex\n",
    "    while i < len(aggregateReturns):\n",
    "        corr = None\n",
    "        cov = None\n",
    "        if maxWindowSize == False:\n",
    "            corr = (aggregateReturns[:i]).corr()\n",
    "            cov = (aggregateReturns[:i]).cov()\n",
    "        else:\n",
    "            corr = (aggregateReturns[i-windowSize:i]).corr()\n",
    "            \n",
    "            cov = (aggregateReturns[i-windowSize:i]).cov()\n",
    "        try:\n",
    "            weights = hrp.getHRP(cov, corr)\n",
    "        #     display(weights)\n",
    "        #     display(aggregateReturns[i+windowSize:i+windowSize+1])\n",
    "            todayReturn = aggregateReturns[i:i+1] * weights\n",
    "        #     display(todayReturn)\n",
    "            sumReturn = pd.DataFrame(todayReturn.apply(lambda x:sum(x), axis=1))\n",
    "            hrpReturns = pd.concat([hrpReturns, sumReturn])\n",
    "            thisWeights = pd.DataFrame([[weights[item] for item in weights.index]], index=sumReturn.index, columns=weights.index.tolist())\n",
    "            historicalWeights = pd.concat([historicalWeights, thisWeights])\n",
    "        except:\n",
    "            print(\"FAILED:\",i)\n",
    "        i += 1\n",
    "    return hrpReturns, historicalWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def storeDiscoveredPortfolio(models, portfolioType, benchmark, IS_DATA, OOS_DATA):\n",
    "    description = \"AUTO GENERATED\"\n",
    "    seenTickers = []\n",
    "    \n",
    "    allHashes = []\n",
    "    for model in models:\n",
    "        allHashes.append(model.getHash())\n",
    "        if model.targetTicker not in seenTickers:\n",
    "            seenTickers.append(model.targetTicker)\n",
    "        \n",
    "    ##SORT SO ENSURE SAME PORTFOLIO NOT CREATED TWICE\n",
    "    allHashes = sorted(allHashes)\n",
    "    \n",
    "    portfolioString = str(allHashes) + benchmark + description + portfolioType\n",
    "    portfolioHash = hashlib.sha224(portfolioString.encode('utf-8')).hexdigest()\n",
    "    print(\"PORTFOLIO HASH:\", portfolioHash)\n",
    "    for hashing in allHashes:\n",
    "        print(hashing)\n",
    "        \n",
    "    \n",
    "        ##UPLOAD ORGANISM OBJECT\n",
    "        while True:\n",
    "            try:\n",
    "                toUpload = {\n",
    "                    \"portfolio\":portfolioHash,\n",
    "                    \"model\":hashing\n",
    "                }\n",
    "                datastoreClient = datastore.Client('money-maker-1236')\n",
    "                #HASH DIGEST\n",
    "                key = datastoreClient.key(params.discoveredPortfolioModels, hashlib.sha224(str(hashing + portfolioHash).encode('utf-8')).hexdigest()) #NEED TO HASH TO ENSURE UNDER COUNT\n",
    "                organismToStore = datastore.Entity(key=key)\n",
    "                organismToStore.update(toUpload)\n",
    "                datastoreClient.put(organismToStore)\n",
    "                break\n",
    "            except:\n",
    "                print(\"UPLOAD ERROR:\", str(sys.exc_info()))\n",
    "                time.sleep(10)\n",
    "    \n",
    "    ##STORE PORTFOLIO OBJECT\n",
    "    while True:\n",
    "        try:\n",
    "            toUpload = {\n",
    "                \"description\":description,\n",
    "                \"benchmark\":benchmark,\n",
    "                \"portfolioType\":portfolioType,\n",
    "                \"startedTrading\":curveTreeDB.getToday()\n",
    "            }\n",
    "            \n",
    "            for k in IS_DATA:\n",
    "                toUpload[\"IS_\"+ k] = IS_DATA[k]\n",
    "            \n",
    "            for k in OOS_DATA:\n",
    "                toUpload[\"OOS_\"+ k] = OOS_DATA[k]\n",
    "                \n",
    "            for ticker in seenTickers:\n",
    "                toUpload[ticker] = True\n",
    "            \n",
    "            toUpload[\"TICKERS TRADED\"] = len(seenTickers)\n",
    "            \n",
    "            datastoreClient = datastore.Client('money-maker-1236')\n",
    "            #HASH DIGEST\n",
    "            key = datastoreClient.key(params.discoveredPortfolios, portfolioHash) #NEED TO HASH TO ENSURE UNDER COUNT\n",
    "            organismToStore = datastore.Entity(key=key)\n",
    "            organismToStore.update(toUpload)\n",
    "            datastoreClient.put(organismToStore)\n",
    "            return portfolioHash\n",
    "            break\n",
    "        except:\n",
    "            print(\"UPLOAD ERROR:\", str(sys.exc_info()))\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWeightingForAlgos(allModels, columns):\n",
    "    countPerTicker = {}\n",
    "    hashes = {}\n",
    "    for mod in allModels:\n",
    "        hashes[mod.getHash()] = mod.targetTicker\n",
    "        if mod.targetTicker not in countPerTicker:\n",
    "            countPerTicker[mod.targetTicker] = 0.0\n",
    "        countPerTicker[mod.targetTicker] += 1.0\n",
    "    weightsToSend = []\n",
    "    for col in columns:\n",
    "        weightsToSend.append(1.0/countPerTicker[hashes[col]])\n",
    "        \n",
    "    return [item/sum(weightsToSend) for item in weightsToSend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarizeReturns(returnArr):\n",
    "    newArr = []\n",
    "    for item in returnArr:\n",
    "        if item > 0.0:\n",
    "            newArr.append(1.0)\n",
    "        elif item < 0.0:\n",
    "            newArr.append(-1.0)\n",
    "        else:\n",
    "            newArr.append(0.0)\n",
    "    return newArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performPortfolioPerformanceEstimation(historicalPredictions, historicalReturns, factorToTrade, portfolioType, hashToModel, joinedData):\n",
    "    returnWindows = [(0, historicalReturns[:450]), (450, historicalReturns)]\n",
    "    historicalWeights = None\n",
    "    for selectedReturns in returnWindows:\n",
    "        startIndex = selectedReturns[0]\n",
    "        returnWindow = selectedReturns[1]\n",
    "        weightsSeen = None\n",
    "        if portfolioType == \"HRP FULL\":\n",
    "            hrpReturns, weightsSeen = produceHRPPredictions(returnWindow,\\\n",
    "                    126, startIndex=max(startIndex, 126), maxWindowSize=False)\n",
    "        elif portfolioType == \"HRP BINARY\":\n",
    "            hrpReturns, weightsSeen = produceHRPPredictions(pd.DataFrame(returnWindow.apply(lambda x:binarizeReturns(x), axis=1)),\\\n",
    "                    126, startIndex=max(startIndex, 126), maxWindowSize=False)\n",
    "        elif portfolioType == \"HRP WINDOW\":\n",
    "            hrpReturns, weightsSeen = produceHRPPredictions(returnWindow,\\\n",
    "                    126, startIndex=max(startIndex, 126), maxWindowSize=True)\n",
    "        elif portfolioType == \"EW\":\n",
    "            weightsSeen = pd.DataFrame(returnWindow.apply(lambda x: [1.0/len(x) for item in x], axis=1), columns=returnWindow.columns.values)\n",
    "        elif portfolioType == \"EW By Ticker\":\n",
    "            weightArray = getWeightingForAlgos(allModels, returnWindow.columns)\n",
    "            weightsSeen = pd.DataFrame(returnWindow.apply(lambda x: weightArray, axis=1), columns=returnWindow.columns.values)\n",
    "            \n",
    "        \n",
    "        \n",
    "        if historicalWeights is None:\n",
    "            historicalWeights = weightsSeen\n",
    "        else:\n",
    "            historicalWeights = pd.concat([historicalWeights, weightsSeen])\n",
    "        \n",
    "        \n",
    "        modelsUsed = []\n",
    "\n",
    "        tickersSeen = {}\n",
    "\n",
    "        for modelHash in historicalPredictions.columns:\n",
    "            thisModel = hashToModel[modelHash]\n",
    "            modelsUsed.append(thisModel)\n",
    "        if startIndex == 0:\n",
    "            scaledStats = getLimitedDataForPortfolio(historicalWeights,\\\n",
    "                                    historicalPredictions, modelsUsed, factorToTrade, joinedData)\n",
    "            print(scaledStats)\n",
    "            if scaledStats[\"sharpe difference\"] < 0.0 or scaledStats[\"annualizedReturn\"] < scaledStats[\"annualizedVolatility\"]:\n",
    "                return None, None\n",
    "    \n",
    "    trainStats = getLimitedDataForPortfolio(historicalWeights[:-252], \\\n",
    "                                              historicalPredictions, modelsUsed, factorToTrade, joinedData)\n",
    "    testStats = getLimitedDataForPortfolio(historicalWeights[-252:], \\\n",
    "                                              historicalPredictions, modelsUsed, factorToTrade, joinedData)\n",
    "    \n",
    "    if trainStats[\"sharpe difference\"] > 0.0 and trainStats[\"annualizedReturn\"] > trainStats[\"annualizedVolatility\"]:\n",
    "        print(\"ACCEPTED\", trainStats, testStats)\n",
    "#         storeDiscoveredPortfolio(modelsUsed, portfolioType, factorToTrade, trainStats, testStats)\n",
    "    else:\n",
    "        print(\"FAILED\", trainStats)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = [\"EW\", \"HRP BINARY\", \"EW\", \"HRP WINDOW\", \"HRP FULL\", \"EW By Ticker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MP RUN  \n",
    "\n",
    "def createPossiblePortfoliosMP(cleanedPredictions, cleanedReturns, hashToModel, joinedData, threadsToUse):\n",
    "    mpEngine = mp.get_context('fork')\n",
    "        \n",
    "    runningP = []\n",
    "    while True:\n",
    "        selectedAlgorithms = returnSelectAlgos(cleanedReturns.columns)\n",
    "        factorToTrade = \"VTI\"#hashToModel[selectedAlgorithms[random.randint(0, len(selectedAlgorithms) - 1)]].targetTicker\n",
    "        \n",
    "        while len(runningP) > threadsToUse:\n",
    "            runningP = dataAck.cycleP(runningP)\n",
    "            \n",
    "        portfolioType = types[random.randint(0, len(types) - 1)]\n",
    "        print(factorToTrade, len(selectedAlgorithms), portfolioType)\n",
    "        \n",
    "        p = mpEngine.Process(target=performPortfolioPerformanceEstimation, args=(cleanedPredictions[selectedAlgorithms],\\\n",
    "                    cleanedReturns[selectedAlgorithms], factorToTrade, portfolioType, hashToModel, joinedData))\n",
    "        p.start()\n",
    "        runningP.append(p)\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"STARTING GENERATION\")\n",
    "\n",
    "##REMOVE BREAK TO DO FULL AUTO\n",
    "createPossiblePortfoliosMP(cleanedPredictions, cleanedReturns, hashToModel, joinedData, threadsToUse=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
