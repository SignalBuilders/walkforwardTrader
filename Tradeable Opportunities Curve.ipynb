{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import multiprocessing as mp\n",
    "import empyrical\n",
    "import portfolioGeneration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dataAck\n",
    "import portfolio\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import params\n",
    "from google.cloud import datastore, storage, logging\n",
    "import time\n",
    "import pickle\n",
    "import hashlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TradeableCurvePredictor:\n",
    "    def __init__(self, inputSeries, targetTicker, lookbackDistance, predictionDistance, radius, minConfidence, minNeighbors, tradeableMinReturn):\n",
    "        self.parallelism = 16\n",
    "        self.inputSeries = inputSeries\n",
    "        self.targetTicker = targetTicker\n",
    "        self.lookbackDistance = lookbackDistance\n",
    "        self.predictionDistance = predictionDistance\n",
    "        self.radius = radius\n",
    "        self.minConfidence = minConfidence\n",
    "        self.minNeighbors = minNeighbors\n",
    "        self.tradeableMinReturn = tradeableMinReturn\n",
    "    \n",
    "    def describe(self):\n",
    "        return (self.inputSeries.describe(), self.targetTicker, self.lookbackDistance, self.predictionDistance, self.radius, self.minConfidence, self.minNeighbors, self.tradeableMinReturn)\n",
    "\n",
    "    def getHash(self):\n",
    "        return hashlib.sha224(str(self.describe()).encode('utf-8')).hexdigest()\n",
    "\n",
    "    def getReverseHash(self):\n",
    "        return self.getHash()\n",
    "\n",
    "    def getAllHashes(self):\n",
    "        return [self.getHash()]\n",
    "\n",
    "    def formUploadDictionary(self):\n",
    "        toUpload = {}\n",
    "        toUpload[\"ticker\"] = self.targetTicker\n",
    "        toUpload[\"predictionLength\"] = self.predictionDistance\n",
    "        toUpload[\"lookbackDistance\"] = self.lookbackDistance\n",
    "        toUpload[\"radius\"] = self.radius\n",
    "        toUpload[\"minConfidence\"] = self.minConfidence\n",
    "        toUpload[\"minNeighbors\"] = self.minNeighbors\n",
    "        toUpload[\"series\"] = str(self.inputSeries.describe())\n",
    "        toUpload[\"tradeableMinReturn\"] = self.tradeableMinReturn\n",
    "        return toUpload\n",
    "\n",
    "    def numberOfPredictors(self):\n",
    "        return 1\n",
    "\n",
    "    def returnAllTickersInvolved(self):\n",
    "        return [self.targetTicker, self.inputSeries.ticker]\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def ensureNoShifts(nearestIndicies):\n",
    "        breadth = 5\n",
    "        keptIndicies = []\n",
    "        for item in nearestIndicies:\n",
    "            k = item-breadth\n",
    "            shouldAdd = True\n",
    "            while k < item + breadth:\n",
    "                if k in keptIndicies:\n",
    "                    shouldAdd = False\n",
    "                    break\n",
    "                k += 1\n",
    "            if shouldAdd == True:\n",
    "                keptIndicies.append(item)\n",
    "        return keptIndicies\n",
    "    \n",
    "    def generateWindowReturn(self, predictions, short):\n",
    "        if predictions[0] > 0: ##OTHERWISE INVALID\n",
    "            return predictions[2] if short == False else -predictions[2]\n",
    "        return 0.0 ##NO POSITION TAKEN\n",
    "    \n",
    "    @staticmethod\n",
    "    def computePosition(predictionsArr):\n",
    "        netPos = 0.0\n",
    "        for item in predictionsArr:\n",
    "            if item > 0.0:\n",
    "                netPos += 1.0\n",
    "\n",
    "        return netPos/len(predictionsArr)\n",
    "    \n",
    "    @staticmethod\n",
    "    def enforceBuyPreference(returns):\n",
    "        ##ASSUME SHORT ON LEFT\n",
    "        if returns[0] != 0 and returns[1] != 0:\n",
    "            return returns[1]\n",
    "        elif returns[0] == 0 and returns[1] != 0:\n",
    "            return returns[1]\n",
    "        elif returns[0] != 0 and returns[1] == 0:\n",
    "            return returns[0]\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    def generateWindows(self, joinedData):\n",
    "        transformedSeries = pd.DataFrame(self.inputSeries.transformJoinedData(joinedData))\n",
    "        transformedSeries.columns = [\"INPUT\"]\n",
    "        targetSeries = pd.DataFrame(dataAck.createPriceSeries(joinedData, self.targetTicker))\n",
    "        targetSeries.columns = [\"OUTPUT\"]\n",
    "        \n",
    "        joinedTrain = targetSeries.join(transformedSeries).dropna() ##DONE TO ENSURE SAME INDEXES\n",
    "        \n",
    "        inputData = joinedTrain[[\"INPUT\"]].values\n",
    "        outputData = joinedTrain[[\"OUTPUT\"]].values\n",
    "        outputDays = joinedTrain[[\"OUTPUT\"]].index\n",
    "        \n",
    "        xVals = []\n",
    "        yValsShort = []\n",
    "        yValsLong = []\n",
    "        yVals = []\n",
    "        yIndex = []\n",
    "        for i in range(len(inputData) - self.lookbackDistance - self.lookbackDistance - self.predictionDistance):\n",
    "            xVals.append(MinMaxScaler().fit_transform(inputData[i:i+self.lookbackDistance]).flatten())\n",
    "            ##SKIP LOOKBACK DISTANCE * 2 TO AVOID ANY OVERLAP WITH ANYTHING IN TRAINING\n",
    "            targetArr = outputData[i+self.lookbackDistance + self.lookbackDistance:i+self.lookbackDistance+self.lookbackDistance+self.predictionDistance]\n",
    "            daysArr = outputDays[i+self.lookbackDistance + self.lookbackDistance:i+self.lookbackDistance+self.lookbackDistance+self.predictionDistance]\n",
    "            \n",
    "            \n",
    "            ##SET yVAL FOR BOTH SHORT AND LONG TRADEABLE OPPORTUNITY\n",
    "            yValsShort.append(abs(min([(item - targetArr[0])/targetArr[0] for item in targetArr]))[0] if abs(min([(item - targetArr[0])/targetArr[0] for item in targetArr]))[0] > self.tradeableMinReturn else 0.0)\n",
    "            yValsLong.append(abs(max([(item - targetArr[0])/targetArr[0] for item in targetArr]))[0] if abs(max([(item - targetArr[0])/targetArr[0] for item in targetArr]))[0] > self.tradeableMinReturn else 0.0)\n",
    "            yVals.append((targetArr[-1] - targetArr[0])/targetArr[0])\n",
    "            yIndex.append(daysArr[0])\n",
    "        return xVals, yValsShort, yValsLong, yVals, yIndex, MinMaxScaler().fit_transform(transformedSeries[-self.lookbackDistance:]).flatten()\n",
    "    \n",
    "    def runDay(self, xVals, yValsShort, yValsLong, xTarget, identifier=None, sharedDict=None):\n",
    "        \n",
    "        \n",
    "        nn = NearestNeighbors(p=2, n_jobs = 1)\n",
    "        nn.fit(xVals)\n",
    "        closest = nn.radius_neighbors([xTarget], self.radius)\n",
    "        keptNeighbors = TradeableCurvePredictor.ensureNoShifts(closest[1][0])\n",
    "        shortPred = 0.0\n",
    "        longPred = 0.0\n",
    "        if len(keptNeighbors) > self.minNeighbors:\n",
    "            shortPredictions = []\n",
    "            for sampleIndex in keptNeighbors:\n",
    "                shortPredictions.append(yValsShort[sampleIndex])\n",
    "            shortPredictions = np.array(shortPredictions)\n",
    "\n",
    "            shortPred = len(shortPredictions[shortPredictions > 0])/float(len(shortPredictions))\n",
    "            \n",
    "            longPredictions = []\n",
    "            for sampleIndex in keptNeighbors:\n",
    "                longPredictions.append(yValsLong[sampleIndex])\n",
    "            longPredictions = np.array(longPredictions)\n",
    "\n",
    "            longPred = len(longPredictions[longPredictions > 0])/float(len(longPredictions))\n",
    "        \n",
    "        if shortPred < self.minConfidence:\n",
    "            shortPred = 0.0\n",
    "         \n",
    "        if longPred < self.minConfidence:\n",
    "            longPred = 0.0\n",
    "        \n",
    "        toRet = {\n",
    "            \"short\":shortPred,\n",
    "            \"long\":longPred\n",
    "        }\n",
    "        if identifier is not None:\n",
    "            sharedDict[identifier] = toRet\n",
    "        else:\n",
    "            return toRet\n",
    "    \n",
    "    def runDayChunking(self, xVals, yValsShort, yValsLong, identifiers, sharedDict, k):\n",
    "        j= 0\n",
    "        for i in identifiers:\n",
    "            pred = self.runDay(xVals[:int(i)],  yValsShort[:int(i)], yValsLong[:int(i)], xVals[int(i)+44])\n",
    "            sharedDict[str(i)] = pred\n",
    "            j += 1\n",
    "            if j % 30 == 0:\n",
    "                print(\"THREAD \", k, \"PROGRESS:\", j/len(identifiers))\n",
    "        \n",
    "    \n",
    "    def runModelsChunksSkipMP(self, dataOfInterest, daysToCheck = None, earlyStop=False):\n",
    "        xVals, yValsShort, yValsLong, yVals, yIndex, xToday = self.generateWindows(dataOfInterest)\n",
    "        mpEngine = mp.get_context('fork')\n",
    "        with mpEngine.Manager() as manager:\n",
    "            returnDict = manager.dict()\n",
    "            \n",
    "            identifiersToCheck = []\n",
    "            \n",
    "            for i in range(len(xVals) - 44): ##44 is lag...should not overlap with any other predictions or will ruin validity of walkforward optimization\n",
    "                if i < 600:\n",
    "                    ##MIN TRAINING\n",
    "                    continue\n",
    "                identifiersToCheck.append(str(i))\n",
    "                \n",
    "            if daysToCheck is not None:\n",
    "                identifiersToCheck = identifiersToCheck[-daysToCheck:]\n",
    "\n",
    "\n",
    "            ##FIRST CHECK FIRST 500 IDENTIFIERS AND THEN IF GOOD CONTINUE\n",
    "            \n",
    "\n",
    "            identifierWindows = [identifiersToCheck[:252], identifiersToCheck[252:600], identifiersToCheck[600:900], identifiersToCheck[900:1200], identifiersToCheck[1200:]] ##EXACTLY TWO YEARS\n",
    "            if earlyStop == False:\n",
    "                identifierWindows = [identifiersToCheck]\n",
    "            \n",
    "            returnStream = None\n",
    "            shortSeen = 0 if earlyStop == True else -1\n",
    "            for clippedIdentifiers in identifierWindows:\n",
    "                \n",
    "                splitIdentifiers = np.array_split(np.array(clippedIdentifiers), 16)\n",
    "                \n",
    "                \n",
    "                runningP = []\n",
    "                k = 0\n",
    "                for identifiers in splitIdentifiers:\n",
    "                    p = mpEngine.Process(target=TradeableCurvePredictor.runDayChunking, args=(self, xVals,  yValsShort, yValsLong, identifiers, returnDict,k))\n",
    "                    p.start()\n",
    "                    runningP.append(p)\n",
    "                    \n",
    "                    k += 1\n",
    "                    \n",
    "\n",
    "                while len(runningP) > 0:\n",
    "                    newP = []\n",
    "                    for p in runningP:\n",
    "                        if p.is_alive() == True:\n",
    "                            newP.append(p)\n",
    "                        else:\n",
    "                            p.join()\n",
    "                    runningP = newP\n",
    "                    \n",
    "                \n",
    "                preds = []\n",
    "                actualShort = []\n",
    "                actualLong = []\n",
    "                actual = []\n",
    "                days = []\n",
    "                for i in clippedIdentifiers:\n",
    "                    preds.append(returnDict[i])\n",
    "                    actualShort.append(yValsShort[int(i) + 44])\n",
    "                    actualLong.append(yValsLong[int(i) + 44])\n",
    "                    actual.append(yVals[int(i) + 44])\n",
    "                    days.append(yIndex[int(i) + 44])\n",
    "                \n",
    "                ##CREATE ACCURATE BLENDING ACROSS DAYS\n",
    "                predsTable = pd.DataFrame(preds, index=days)\n",
    "                \n",
    "                \n",
    "                rawPredictionsShort = pd.DataFrame(predsTable[[\"short\"]], index=days, columns=[\"Predictions\"])\n",
    "                i = 1\n",
    "                tablesToJoin = []\n",
    "                while i < self.predictionDistance:\n",
    "                    thisTable = rawPredictionsShort.shift(i)\n",
    "                    thisTable.columns = [\"Predictions_\" + str(i)]\n",
    "                    tablesToJoin.append(thisTable)\n",
    "                    i += 1\n",
    "                \n",
    "                rawPredictionsShort = rawPredictionsShort.join(tablesToJoin)\n",
    "                \n",
    "                transformedShort = pd.DataFrame(rawPredictionsShort.apply(lambda x:TradeableCurvePredictor.computePosition(x), axis=1), columns=[\"Predictions\"]).dropna()\n",
    "                \n",
    "                \n",
    "                shortTable = transformedShort\\\n",
    "                        .join(pd.DataFrame(actualShort, index=days, columns=[\"actual short\"]))\\\n",
    "                        .join(pd.DataFrame(actual, index=days, columns=[\"actual\"]))\n",
    "                        \n",
    "                shortReturns = pd.DataFrame(shortTable.apply(lambda x:self.generateWindowReturn(x, short=True), axis=1, raw=True), columns=[\"short return\"])\n",
    "                \n",
    "                rawPredictionsLong = pd.DataFrame(predsTable[[\"long\"]], index=days, columns=[\"Predictions\"])\n",
    "                i = 1\n",
    "                tablesToJoin = []\n",
    "                while i < self.predictionDistance:\n",
    "                    thisTable = rawPredictionsShort.shift(i)\n",
    "                    thisTable.columns = [\"Predictions_\" + str(i)]\n",
    "                    tablesToJoin.append(thisTable)\n",
    "                    i += 1\n",
    "                \n",
    "                rawPredictionsLong = rawPredictionsLong.join(tablesToJoin)\n",
    "                \n",
    "                transformedLong = pd.DataFrame(rawPredictionsLong.apply(lambda x:TradeableCurvePredictor.computePosition(x), axis=1), columns=[\"Predictions\"]).dropna()\n",
    "                \n",
    "                \n",
    "                longTable = transformedLong\\\n",
    "                        .join(pd.DataFrame(actualLong, index=days, columns=[\"actual long\"]))\\\n",
    "                        .join(pd.DataFrame(actual, index=days, columns=[\"actual\"]))\n",
    "                \n",
    "                longReturns = pd.DataFrame(longTable.apply(lambda x:self.generateWindowReturn(x, short=False), axis=1, raw=True), columns=[\"long return\"])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                ##OPT FOR BUY RETURN IF BOTH RETURNS VALID\n",
    "                totalReturn = pd.DataFrame(shortReturns.join(longReturns).apply(lambda x: TradeableCurvePredictor.enforceBuyPreference(x), axis=1, raw=True), columns=[\"Total Return\"])\n",
    "                if returnStream is None:\n",
    "                    returnStream = totalReturn\n",
    "                else:\n",
    "                    returnStream = pd.concat([returnStream, totalReturn])\n",
    "                \n",
    "                print(empyrical.cum_returns(returnStream.values)[-1][0])\n",
    "                if empyrical.cum_returns(returnStream.values)[-1][0] <= 0:\n",
    "                    return\n",
    "                \n",
    "#                 i = 1\n",
    "#                 tablesToJoin = []\n",
    "#                 while i < self.predictionDistance:\n",
    "#                     thisTable = predsTable.shift(i)\n",
    "#                     thisTable.columns = [\"Predictions_\" + str(i)]\n",
    "#                     tablesToJoin.append(thisTable)\n",
    "#                     i += 1\n",
    "                \n",
    "#                 predsTable = predsTable.join(tablesToJoin)\n",
    "                \n",
    "#                 transformedPreds = pd.DataFrame(predsTable.apply(lambda x:dataAck.computePosition(x), axis=1), columns=[\"Predictions\"]).dropna()\n",
    "#                 dailyFactorReturn = dataAck.getDailyFactorReturn(self.targetTicker, dataOfInterest)\n",
    "#                 transformedPreds = transformedPreds.join(dailyFactorReturn).dropna()\n",
    "#                 returnStream = pd.DataFrame(transformedPreds.apply(lambda x:x[0] * x[1], axis=1), columns=[\"Algo Return\"]) if returnStream is None else pd.concat([returnStream, pd.DataFrame(transformedPreds.apply(lambda x:x[0] * x[1], axis=1), columns=[\"Algo Return\"])])\n",
    "#                 factorReturn = pd.DataFrame(transformedPreds[[\"Factor Return\"]]) if factorReturn is None else pd.concat([factorReturn, pd.DataFrame(transformedPreds[[\"Factor Return\"]])])\n",
    "#                 predictions = pd.DataFrame(transformedPreds[[\"Predictions\"]]) if predictions is None else pd.concat([predictions, pd.DataFrame(transformedPreds[[\"Predictions\"]])])\n",
    "\n",
    "#                 alpha, beta = empyrical.alpha_beta(returnStream, factorReturn)\n",
    "#                 activity = np.count_nonzero(returnStream)/float(len(returnStream))\n",
    "#                 rawBeta = abs(empyrical.alpha_beta(returnStream.apply(lambda x:dataAck.applyBinary(x), axis=0), factorReturn.apply(lambda x:dataAck.applyBinary(x), axis=0))[1])\n",
    "#                 shortSharpe = empyrical.sharpe_ratio(returnStream)\n",
    "#                 activity = np.count_nonzero(returnStream)/float(len(returnStream))\n",
    "#                 algoAnnualReturn = empyrical.annual_return(returnStream.values)[0]\n",
    "#                 algoVol = empyrical.annual_volatility(returnStream.values)\n",
    "#                 factorAnnualReturn = empyrical.annual_return(factorReturn.values)[0]\n",
    "#                 factorVol = empyrical.annual_volatility(factorReturn.values)\n",
    "#                 treynor = ((empyrical.annual_return(returnStream.values)[0] - empyrical.annual_return(factorReturn.values)[0]) \\\n",
    "#                            / abs(empyrical.beta(returnStream, factorReturn)))\n",
    "#                 sharpeDiff = empyrical.sharpe_ratio(returnStream) - empyrical.sharpe_ratio(factorReturn)\n",
    "#                 relativeSharpe = sharpeDiff / empyrical.sharpe_ratio(factorReturn) * (empyrical.sharpe_ratio(factorReturn)/abs(empyrical.sharpe_ratio(factorReturn)))\n",
    "#                 stability = empyrical.stability_of_timeseries(returnStream)\n",
    "\n",
    "#                 ##CALCULATE SHARPE WITH SLIPPAGE\n",
    "#                 estimatedSlippageLoss = portfolioGeneration.estimateTransactionCost(predictions)\n",
    "#                 estimatedSlippageLoss.columns = returnStream.columns\n",
    "#                 slippageAdjustedReturn = (returnStream - estimatedSlippageLoss).dropna()\n",
    "#                 slippageSharpe = empyrical.sharpe_ratio(slippageAdjustedReturn)\n",
    "#                 sharpeDiffSlippage = empyrical.sharpe_ratio(slippageAdjustedReturn) - empyrical.sharpe_ratio(factorReturn)\n",
    "#                 relativeSharpeSlippage = sharpeDiffSlippage / empyrical.sharpe_ratio(factorReturn) * (empyrical.sharpe_ratio(factorReturn)/abs(empyrical.sharpe_ratio(factorReturn)))\n",
    "                \n",
    "#                 if np.isnan(shortSharpe) == True:\n",
    "#                     return None, {\"sharpe\":shortSharpe}, None, None, None\n",
    "\n",
    "#                 elif (empyrical.sharpe_ratio(returnStream) < 0.0  or activity < 0.3 or abs(rawBeta) > 0.6 or stability < 0.3) and shortSeen == 0:\n",
    "#                     return None, {\n",
    "#                             \"sharpe\":shortSharpe, ##OVERLOADED IN FAIL\n",
    "#                             \"activity\":activity,\n",
    "#                             \"factorSharpe\":empyrical.sharpe_ratio(factorReturn),\n",
    "#                             \"sharpeSlippage\":slippageSharpe,\n",
    "#                             \"beta\":abs(beta),\n",
    "#                             \"alpha\":alpha,\n",
    "#                             \"activity\":activity,\n",
    "#                             \"treynor\":treynor,\n",
    "#                             \"period\":\"first 252 days\",\n",
    "#                             \"algoReturn\":algoAnnualReturn,\n",
    "#                             \"algoVol\":algoVol,\n",
    "#                             \"factorReturn\":factorAnnualReturn,\n",
    "#                             \"factorVol\":factorVol,\n",
    "#                             \"sharpeDiff\":sharpeDiff,\n",
    "#                             \"relativeSharpe\":relativeSharpe,\n",
    "#                             \"sharpeDiffSlippage\":sharpeDiffSlippage,\n",
    "#                             \"relativeSharpeSlippage\":relativeSharpeSlippage,\n",
    "#                             \"rawBeta\":rawBeta,\n",
    "#                             \"stability\":stability\n",
    "#                     }, None, None, None\n",
    "                \n",
    "#                 elif (((empyrical.sharpe_ratio(returnStream) < 0.25 and sharpeDiff < 0.0) and shortSeen == 1) or ((empyrical.sharpe_ratio(returnStream) < 0.4 and sharpeDiff < 0.0) and (shortSeen == 2 or shortSeen == 3)) or abs(rawBeta) > 0.6 or activity < 0.3 or stability < 0.4) and (shortSeen == 1 or shortSeen == 2 or shortSeen == 3):\n",
    "#                     periodName = \"first 600 days\"\n",
    "#                     if shortSeen == 2:\n",
    "#                         periodName = \"first 900 days\"\n",
    "#                     elif shortSeen == 3:\n",
    "#                         periodName = \"first 1200 days\"\n",
    "#                     return None, {\n",
    "#                             \"sharpe\":shortSharpe, ##OVERLOADED IN FAIL\n",
    "#                             \"activity\":activity,\n",
    "#                             \"factorSharpe\":empyrical.sharpe_ratio(factorReturn),\n",
    "#                             \"sharpeSlippage\":slippageSharpe,\n",
    "#                             \"alpha\":alpha,\n",
    "#                             \"beta\":abs(beta),\n",
    "#                             \"activity\":activity,\n",
    "#                             \"treynor\":treynor,\n",
    "#                             \"period\":periodName,\n",
    "#                             \"algoReturn\":algoAnnualReturn,\n",
    "#                             \"algoVol\":algoVol,\n",
    "#                             \"factorReturn\":factorAnnualReturn,\n",
    "#                             \"factorVol\":factorVol,\n",
    "#                             \"sharpeDiff\":sharpeDiff,\n",
    "#                             \"relativeSharpe\":relativeSharpe,\n",
    "#                             \"sharpeDiffSlippage\":sharpeDiffSlippage,\n",
    "#                             \"relativeSharpeSlippage\":relativeSharpeSlippage,\n",
    "#                             \"rawBeta\":rawBeta,\n",
    "#                             \"stability\":stability\n",
    "#                     }, None, None, None\n",
    "                    \n",
    "#                 elif shortSeen < 4:\n",
    "#                     print(\"CONTINUING\", \"SHARPE:\", shortSharpe, \"SHARPE DIFF:\", sharpeDiff, \"RAW BETA:\", rawBeta, \"TREYNOR:\", treynor)\n",
    "               \n",
    "#                 shortSeen += 1\n",
    "\n",
    "#             return returnStream, factorReturn, predictions, slippageAdjustedReturn, rawPredictions\n",
    "    \n",
    "    def runModelHistorical(self, dataOfInterest, earlyStop=False):\n",
    "        return self.runModelsChunksSkipMP(dataOfInterest, earlyStop=earlyStop)\n",
    "\n",
    "\n",
    "#     def runModelToday(self, dataOfInterest):\n",
    "#         xVals, yVals, yIndex, xToday = self.generateWindows(dataOfInterest)\n",
    "#         return self.runDay(xVals, yVals, xToday, identifier=None, sharedDict=None)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEM\n",
      "ATTEMPTING PULL EEM\n",
      "['AGG', 'DIA', 'DVY', 'DXJ', 'EFA', 'EWC', 'EWG', 'EWH', 'EWJ', 'EWT', 'EWU', 'EWW', 'FEZ', 'FXE', 'GDX', 'GLD', 'IAU', 'IBB', 'IEF', 'IJH', 'IJR', 'ITB', 'IVE', 'IVV', 'IVW', 'IWB', 'IWD', 'IWF', 'IWM', 'IWN', 'IWO', 'IWR', 'IYF', 'IYR', 'IYT', 'KBE', 'KRE', 'LQD', 'MDY', 'OEF', 'OIH', 'QQQ', 'RSP', 'SDY', 'SH', 'SHY', 'SLV', 'SMH', 'SOXX', 'SPY', 'TIP', 'TLT', 'USO', 'VB', 'VBR', 'VFH', 'VGK', 'VGT', 'VIG', 'VNQ', 'VO', 'VTI', 'VTV', 'VUG', 'XBI', 'XHB', 'XLB', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLU', 'XLV', 'XLY', 'XRT', 'EEM']\n",
      "*********\n",
      "NEW SERIES ('XLV', 40, 19, None, 4)\n",
      "*********\n",
      "(('XLV', 40, 19, None, 4), 'EEM', 5, 2, 0.3, 0.3, 10, 0.01)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 2 elements, new values have 1 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a335486ee3a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m                                 \u001b[0mcPre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTradeableCurvePredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtickerToTrade\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminConfidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtradeableMinReturn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcPre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                                 \u001b[0mtotalReturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunModelHistorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoinedData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlyStop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-893b678e24cd>\u001b[0m in \u001b[0;36mrunModelHistorical\u001b[0;34m(self, dataOfInterest, earlyStop)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrunModelHistorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataOfInterest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlyStop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunModelsChunksSkipMP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataOfInterest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlyStop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearlyStop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-893b678e24cd>\u001b[0m in \u001b[0;36mrunModelsChunksSkipMP\u001b[0;34m(self, dataOfInterest, daysToCheck, earlyStop)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictionDistance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                     \u001b[0mthisTable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawPredictionsShort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                     \u001b[0mthisTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Predictions_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                     \u001b[0mtablesToJoin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrickogrady/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3092\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3094\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3095\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3096\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.AxisProperty.__set__ (pandas/_libs/lib.c:45255)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/patrickogrady/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrickogrady/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m   2834\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[1;32m   2835\u001b[0m                              \u001b[0;34m'new values have %d elements'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2836\u001b[0;31m                              (old_len, new_len))\n\u001b[0m\u001b[1;32m   2837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 2 elements, new values have 1 elements"
     ]
    }
   ],
   "source": [
    "import dataAck\n",
    "import portfolio\n",
    "import TreePredictor\n",
    "import curveTreeDB\n",
    "import params\n",
    "\n",
    "\n",
    "allTickers = dataAck.getAllTickersPlain()\n",
    "while True:\n",
    "    import random\n",
    "    ##ADVANCED TICKER TO TRADE SELECTION\n",
    "#     modelCount, modelSplitByTicker, predictionCount, numPredictors = curveTreeDB.getModelCounts(params.curveModels)\n",
    "\n",
    "#     validTickersToTrade = []\n",
    "\n",
    "#     for ticker in allTickers:\n",
    "#         if ticker not in modelSplitByTicker:\n",
    "#             validTickersToTrade.append(ticker)\n",
    "#             print(\"NOT PRESENT\", ticker)\n",
    "\n",
    "#     if len(validTickersToTrade) == 0:\n",
    "#         ##MEANS ALL TICKERS HAVE AT LEAST ONE MODEL\n",
    "#         for ticker in sorted(modelSplitByTicker, key=modelSplitByTicker.get)[:40]:\n",
    "#             validTickersToTrade.append(ticker)\n",
    "#             print(ticker, modelSplitByTicker[ticker])\n",
    "\n",
    "\n",
    "\n",
    "    tickerToTrade = \"EEM\"#validTickersToTrade[random.randint(0, len(validTickersToTrade)) - 1]\n",
    "    print(tickerToTrade)\n",
    "\n",
    "    tData = dataAck.getTrainingData(tickerToTrade)\n",
    "    joinedData = None\n",
    "    validTickers = None\n",
    "\n",
    "\n",
    "\n",
    "    if tData is None:\n",
    "        dataAck.logModel(\"Cache\", {\n",
    "            \"type\":\"miss\",\n",
    "            \"ticker\":tickerToTrade,\n",
    "            \"day\":str(portfolio.getToday())\n",
    "        })\n",
    "\n",
    "        tickersToPull = dataAck.getDataSourcesForTicker(tickerToTrade)\n",
    "        print(tickersToPull)\n",
    "\n",
    "        pulledData, validTickers = dataAck.downloadTickerData(tickersToPull)\n",
    "\n",
    "        joinedData = dataAck.joinDatasets([pulledData[ticker] for ticker in pulledData])\n",
    "\n",
    "        dataAck.storeTrainingData(tickerToTrade, (joinedData, validTickers))\n",
    "    else:\n",
    "        joinedData = tData[0]\n",
    "        validTickers = tData[1]\n",
    "        dataAck.logModel(\"Cache\", {\n",
    "            \"type\":\"hit\",\n",
    "            \"ticker\":tickerToTrade,\n",
    "            \"day\":str(portfolio.getToday())\n",
    "        })\n",
    "\n",
    "\n",
    "    sManager = dataAck.seriesManager(validTickers)\n",
    "    print(sManager.describe())\n",
    "\n",
    "    import time\n",
    "    import warnings\n",
    "    import numpy as np\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    ##GET ALGOS INITIALLY GOOD\n",
    "    runsSeen = 0\n",
    "    while True:\n",
    "        s = sManager.createSeries()\n",
    "        while s.checkValidity(s.transformJoinedData(joinedData[:\"2016-01-01\"])) == False:\n",
    "            s = sManager.createSeries()\n",
    "\n",
    "        print(\"*********\")\n",
    "        print(\"NEW SERIES\", s.describe())\n",
    "        print(\"*********\")\n",
    "\n",
    "        for lookback in [5, 10, 22, 44]:\n",
    "            for prediction in [2, 3, 5, 7, 10, 15]:\n",
    "                for radius in [0.3, 0.5, 0.7, 1.0, 1.5, 2.0]:\n",
    "                    for minConfidence in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "                        for minNeighbors in [5, 10, 20]:\n",
    "                            for tradeableMinReturn in [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.05]:\n",
    "                                if random.uniform(0,1) < 0.97: ##RANDOMLY SKIP A LOT...FAILING FAST ON SERIES ALLOWS US TO EXAMINE MUCH LARGER SAMPLE SPACE\n",
    "                                    continue\n",
    "                                cPre = TradeableCurvePredictor(s, tickerToTrade, lookback, prediction, radius, minConfidence, minNeighbors, tradeableMinReturn)\n",
    "                                print(cPre.describe())\n",
    "                                totalReturn = cPre.runModelHistorical(joinedData, earlyStop=True)\n",
    "                                \n",
    "  \n",
    "\n",
    "\n",
    "        runsSeen += 1\n",
    "\n",
    "        if runsSeen > 40:\n",
    "            break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
